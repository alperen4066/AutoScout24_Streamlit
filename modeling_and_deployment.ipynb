{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UCsvzbImqZN"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5WapR8JmqZN"
   },
   "source": [
    "# WELCOME!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyeGWbuTmqZN"
   },
   "source": [
    "Welcome to \"***Car Price Prediction Project***\". This is the first medium project of ***Machine Learning*** course. In this project you will have the opportunity to apply many algorithms commonly used for regression problems.\n",
    "\n",
    "Also, you will apply various processes such as pre-processing, ***train-test spilit*** and ***cross validation*** that you will use in algorithm modeling and prediction processes in Python with ***scikit-learn***. \n",
    "\n",
    "Before diving into the project, please take a look at the determines and tasks.\n",
    "\n",
    "- **NOTE:** This project assumes that you already know the basics of coding in Python. You should also be familiar with the theory behind regression algorithms and scikit-learn module as well as Machine Learning before you begin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0Iul5QymqZN"
   },
   "source": [
    "# #Determines\n",
    "\n",
    "**Auto Scout** data which using for this project, scraped from the on-line car trading company(https://www.autoscout24.com)in 2019, contains many features of 9 different car models. In this project, you will use the data set which is already preprocessed and prepared for algorithms .\n",
    "\n",
    "The aim of this project to understand of machine learning algorithms. Therefore, you will not need any EDA process as you will be working on the edited data.\n",
    "\n",
    "---\n",
    "\n",
    "In this Senario, you will estimate the prices of cars using regression algorithms.\n",
    "\n",
    "While starting you should import the necessary modules and load the data given as pkl file. Also you'll need to do a few pre-processing before moving to modelling. After that you will implement ***Linear Regression, Ridge Regression, Lasso Regression,and Elastic-Net algorithms respectively*** (After completion of Unsupervised Learning section, you can also add bagging and boosting algorithms such as ***Random Forest and XG Boost*** this notebook to develop the project. You can measure the success of your models with regression evaluation metrics as well as with cross validation method.\n",
    "\n",
    "For the better results, you should try to increase the success of your models by performing hyperparameter tuning. Determine feature importances for the model. You can set your model with the most important features for resource saving. You should try to apply this especially in Random Forest and XG Boost algorithms. Unlike the others, you will perform hyperparameter tuning for Random Forest and XG Boost using the ***GridSearchCV*** method. \n",
    "\n",
    "Finally You can compare the performances of algorithms, work more on the algorithm have the most successful prediction rate.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pL-jJ1irmqZN"
   },
   "source": [
    "# #Tasks\n",
    "\n",
    "#### 1. Import Modules, Load Data and Data Review\n",
    "#### 2. Data Pre-Processing\n",
    "#### 3. Implement Linear Regression \n",
    "#### 4. Implement Ridge Regression\n",
    "#### 5. Implement Lasso Regression \n",
    "#### 6. Implement Elastic-Net\n",
    "#### 7. Visually Compare Models Performance In a Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rik6d_vimqZN"
   },
   "source": [
    "## 1. Import Modules, Load Data and Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QBddHlqgmqZN"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, MinMaxScaler, RobustScaler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, mean_absolute_error, r2_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd      \n",
    "import numpy as np \n",
    "#import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "pd.set_option('display.max_columns', 500) # 500 sütuna kadar göster\n",
    "pd.set_option('display.max_rows', 500) # 500 satıra kadar göster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_scout_not_dummy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include =\"object\").head()   # sadece object sütunları getiriyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('object'):\n",
    "    print(f\"{col:<20}:\", df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.make_model.value_counts() # Audi A2  1 tane olduğundan atabiliriz modele etkisi yok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.make_model.value_counts().plot(kind =\"bar\")\n",
    "ax.spines['top'].set_visible(False) # tepe çzgisini kaldırdık\n",
    "ax.spines['right'].set_visible(False) # sağ çzigiyi kaldırdık\n",
    "#ax.axis(\"off\")\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.03, p.get_height() * 1.03)) #üzerlerine ağırlıkları yazdırdık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.make_model==\"Audi A2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=[2614], inplace =True) # Audi A2 yi index numarasına göre drop ettik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df.price, bins=50, kde=True) # price 4000$ üstü verin,n normal dağılımını bozduğu görülüyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew(df.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include =\"number\") # numeric değerleri aldık\n",
    "df_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_numeric.corr(), annot =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multicollinearity control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.corr()[(df_numeric.corr()>= 0.9) & (df_numeric.corr() < 1)].any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.corr()[(df_numeric.corr()<= -0.9) & (df_numeric.corr() > -1)].any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.price) # 4000$ üstü outlier görünüyor ama araba grupları için ayrı ayrı bakamak daha sağlıklı, bu bilgi verinin tamamı için geçerlş"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(x=\"make_model\", y=\"price\", data=df, whis=3) # Audi A3, Opel Astra,Opel Insignia,Renault Clio ve Renault Espace de outlier veri görünüyor diğerlerinde yok \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bu sütunlardaki verileri virgülle ayırıp, get dummies yapıp  sütunların başınada kısaltmalarını yazıyor ve df e ekliyor\n",
    "df = df.join(df[\"Comfort_Convenience\"].str.get_dummies(sep = \",\").add_prefix(\"cc_\")) \n",
    "df = df.join(df[\"Entertainment_Media\"].str.get_dummies(sep = \",\").add_prefix(\"em_\"))\n",
    "df = df.join(df[\"Extras\"].str.get_dummies(sep = \",\").add_prefix(\"ex_\"))\n",
    "df = df.join(df[\"Safety_Security\"].str.get_dummies(sep = \",\").add_prefix(\"ss_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Comfort_Convenience\",\"Entertainment_Media\",\"Extras\",\"Safety_Security\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first =True) # ilk sütunları düşürdük fazla ram fazla cpu olmasın diye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_by_price = df.corr()[\"price\"].sort_values()[:-1]\n",
    "corr_by_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "sns.barplot(x = corr_by_price.index, y = corr_by_price)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsEUUAAKmqZN"
   },
   "source": [
    "## 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtVkM6f2mqZN"
   },
   "source": [
    "As you know, the data set must be edited before proceeding to the implementation of the model. As the last step before model fitting, you need to spilit the data set as train and test. Then, you should train the model with train data and evaluate the performance of the model on the test data. You can use the train and test data you have created for all algorithms.\n",
    "\n",
    "You must also drop your target variable, the column you are trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7d_92iemqZN"
   },
   "source": [
    "You can use many [performance metrics for regression](https://medium.com/analytics-vidhya/evaluation-metrics-for-regression-problems-343c4923d922) to measure the performance of the regression model you train. You can define a function to view different metric results together.\n",
    "\n",
    "You can also use the [cross validation](https://towardsdatascience.com/cross-validation-explained-evaluating-estimator-performance-e51e5430ff85) method to measure the estimator performance. Cross validation uses different data samples from your test set and calculates the accuracy score for each data sample. You can calculate the final performance of your estimator by averaging these scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3gMQ3utmqZN"
   },
   "source": [
    "### Train | Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(columns=\"price\")\n",
    "y= df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "An_5ITcAmqZO"
   },
   "source": [
    "## 3. Implement Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c0y-w8vmqZO"
   },
   "source": [
    " - Import the modul\n",
    " - Fit the model \n",
    " - Predict the test set\n",
    " - Determine feature coefficiant\n",
    " - Evaluate model performance (use performance metrics for regression and cross_val_score)\n",
    " - Compare different evaluation metrics\n",
    " \n",
    "*Note: You can use the [dir()](https://www.geeksforgeeks.org/python-dir-function/) function to see the methods you need.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lq6UKn_HmqZO"
   },
   "outputs": [],
   "source": [
    "def train_val(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train) # overfitting var mı yok mu kıyaslamak için\n",
    "    \n",
    "    scores = {\"train\": {\"R2\" : r2_score(y_train, y_train_pred),\n",
    "    \"mae\" : mean_absolute_error(y_train, y_train_pred),\n",
    "    \"mse\" : mean_squared_error(y_train, y_train_pred),                          \n",
    "    \"rmse\" : np.sqrt(mean_squared_error(y_train, y_train_pred))},\n",
    "    \n",
    "    \"test\": {\"R2\" : r2_score(y_test, y_pred),\n",
    "    \"mae\" : mean_absolute_error(y_test, y_pred),\n",
    "    \"mse\" : mean_squared_error(y_test, y_pred),\n",
    "    \"rmse\" : np.sqrt(mean_squared_error(y_test, y_pred))}}\n",
    "    \n",
    "    return pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.3f}'.format #nokta sonrası yorumlama kolay olsun diye sadece 3 basamak aldık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val(lm, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies yaptığımız için sütun sayısı arttı bundan dolayı r2 score da yalancı bir artış olabilir,bakalım\n",
    "# normalde satır ve sütun sayıları dengeli artmalı\n",
    "def adj_r2(y_test, y_pred, df):   \n",
    "    r2 = r2_score(y_test, y_pred) \n",
    "    n = df.shape[0]   # number of observations\n",
    "    p = df.shape[1]-1 # number of independent variables \n",
    "    adj_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "    return adj_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_r2(y_test, y_pred, df) # çok bir değişim olamamış,sıkıntı yok "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "scores = cross_validate(model, X_train, y_train, scoring=['r2', \n",
    "            'neg_mean_absolute_error','neg_mean_squared_error','neg_root_mean_squared_error'], cv =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores).iloc[:, 2:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val(lm, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2405/df.price.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual eğri ile predict eğrisi arasındaki açıklık bariz,\n",
    "# bunu özellikle 30000 sonrası verilerden görüyoruz,bu veriler predict eğrisini uzaklaştırıyor gerçek verilerden\n",
    "from yellowbrick.regressor import PredictionError\n",
    "from yellowbrick.features import RadViz\n",
    "\n",
    "visualizer = RadViz(size=(720, 3000))\n",
    "model = LinearRegression()\n",
    "visualizer = PredictionError(model)\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30000 e kadar eğrinin alt ve üstü simetrik, normal dağılım gösteriyor,sonrası predicts altta kalıyor\n",
    "plt.figure(figsize=(12,8))\n",
    "residuals = y_test-y_pred\n",
    "\n",
    "sns.scatterplot(x = y_test, y = -residuals) #-residuals\n",
    "plt.axhline(y = 0, color =\"r\", linestyle = \"--\")\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "visualizer = RadViz(size=(1000, 720))\n",
    "model = LinearRegression()\n",
    "visualizer = ResidualsPlot(model)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer.show();       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping observations from the dataset that worsen my predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df[~(df.price>35000)] # 35000 sonrasını tahminerimi bozduğundan attık\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.price>35000]) # zaten atılan kısım verinin %3 oluşturur, yani küçük bir kısım "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.price>35000].groupby(\"make_model\").count().iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.make_model.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3.drop(columns = \"price\")\n",
    "y = df3.price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2 = LinearRegression()\n",
    "lm2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = RadViz(size=(720, 3000))\n",
    "model = LinearRegression()\n",
    "visualizer = PredictionError(model)\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val(lm2, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "     train\t      test\n",
    "R2\t 0.890\t      0.890\n",
    "mae\t 1705.452\t  1705.217\n",
    "mse\t 6038122.231  5785150.711\n",
    "rmse 2457.259\t  2405.234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1908/df3.price.mean()    #hatam  %13 den %11 düştü tahminleri bozan kısmı atınca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2405/df2.price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lm2.predict(X_test)\n",
    "\n",
    "lm_R2 = r2_score(y_test, y_pred)\n",
    "lm_mae = mean_absolute_error(y_test, y_pred)\n",
    "lm_rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = { 'Actual': y_test, 'Pred': y_pred, 'Residual': y_test-y_pred }\n",
    "compare = pd.DataFrame(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_sample = compare.sample(20)\n",
    "comp_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_sample.plot(kind='bar',figsize=(15,9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lm2.coef_, index = X.columns, columns=[\"Coef\"]).sort_values(\"Coef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2ROwYsymqZO"
   },
   "source": [
    "## 4. Implement Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RvdF8CRmqZO"
   },
   "source": [
    "- Import the modul \n",
    "- Do not forget to scale the data or use Normalize parameter as True \n",
    "- Fit the model \n",
    "- Predict the test set \n",
    "- Evaluate model performance (use performance metrics for regression) \n",
    "- Tune alpha hiperparameter by using [cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) and determine the optimal alpha value.\n",
    "- Fit the model and predict again with the new alpha value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val(ridge_model, X_train_scaled, y_train, X_test_scaled, y_test) \n",
    "# as seen, no overfitting because Ridge has alreday dealing with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best alpha for Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_space = np.linspace(0.01, 100, 100)\n",
    "alpha_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(random_state=42)\n",
    "\n",
    "param_grid = {'alpha':alpha_space}\n",
    "\n",
    "ridge_grid_model = GridSearchCV(estimator=ridge_model,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='neg_root_mean_squared_error',\n",
    "                          cv=10,\n",
    "                          n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_grid_model.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge_grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_grid_model.best_params_ # best alpha for ridge:1.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ridge_grid_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_grid_model.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val(ridge_grid_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_grid_model.predict(X_test_scaled)\n",
    "rm_R2 = r2_score(y_test, y_pred)\n",
    "rm_mae = mean_absolute_error(y_test, y_pred)\n",
    "rm_rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=1.02, random_state=42).fit(X_train_scaled, y_train)\n",
    "\n",
    "pd.DataFrame(ridge.coef_, index = X.columns, columns=[\"Coef\"]).sort_values(\"Coef\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDfXOSnpmqZO"
   },
   "source": [
    "## 5. Implement Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icqyxzBymqZO"
   },
   "source": [
    "- Import the modul \n",
    "- Do not forget to scale the data or use Normalize parameter as True(If needed)\n",
    "- Fit the model \n",
    "- Predict the test set \n",
    "- Evaluate model performance (use performance metrics for regression) \n",
    "- Tune alpha hyperparameter by using [cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) and determine the optimal alpha value.\n",
    "- Fit the model and predict again with the new alpha value.\n",
    "- Compare different evaluation metrics\n",
    "\n",
    "*Note: To understand the importance of the alpha hyperparameter, you can observe the effects of different alpha values on feature coefficants.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KbGqu0u5mqZO"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso(random_state=42)\n",
    "lasso_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val(lasso_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best alpha for Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso(random_state=42)\n",
    "\n",
    "param_grid = {'alpha':alpha_space}\n",
    "\n",
    "lasso_grid_model = GridSearchCV(estimator=lasso_model,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='neg_root_mean_squared_error',\n",
    "                          cv=10,\n",
    "                          n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_grid_model.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_grid_model.best_params_  # best alpha for lasso : 1.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val(lasso_grid_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso_grid_model.predict(X_test_scaled)\n",
    "lasm_R2 = r2_score(y_test, y_pred)\n",
    "lasm_mae = mean_absolute_error(y_test, y_pred)\n",
    "lasm_rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=1.02, random_state=42).fit(X_train_scaled, y_train)\n",
    "pd.DataFrame(lasso.coef_, index = X.columns, columns=[\"Coef\"]).sort_values(\"Coef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpoOypMbmqZO"
   },
   "source": [
    "## 6. Implement Elastic-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "El7SNJUemqZO"
   },
   "source": [
    "- Import the modul \n",
    "- Do not forget to scale the data or use Normalize parameter as True(If needed)\n",
    "- Fit the model \n",
    "- Predict the test set \n",
    "- Evaluate model performance (use performance metrics for regression) \n",
    "- Tune alpha hyperparameter by using [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) and determine the optimal alpha value.\n",
    "- Fit the model and predict again with the new alpha value.\n",
    "- Compare different evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKVr6v2JmqZO"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_model = ElasticNet(random_state=42)\n",
    "elastic_model.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val(elastic_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best alpha and l1_ratio for ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_model = ElasticNet(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[1.02, 2,  3, 4, 5, 7, 10, 11],\n",
    "              'l1_ratio':[.5, .7, .9, .95, .99, 1]}\n",
    "\n",
    "elastic_grid_model = GridSearchCV(estimator=elastic_model,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='neg_root_mean_squared_error',\n",
    "                          cv=10,\n",
    "                          n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_grid_model.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_grid_model.best_params_   # best alpha and l1_ratio for elasticnet: 1.02 and  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val(elastic_grid_model, X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = elastic_grid_model.predict(X_test_scaled)\n",
    "em_R2 = r2_score(y_test, y_pred)\n",
    "em_mae = mean_absolute_error(y_test, y_pred)\n",
    "em_rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature İmportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from yellowbrick.features import RadViz\n",
    "\n",
    "\n",
    "viz = FeatureImportances(Lasso(alpha=1.02), labels=X_train.columns)\n",
    "visualizer = RadViz(size=(720, 3000))\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df2[[\"make_model\", \"hp_kW\", \"km\",\"age\", \"price\", \"Gearing_Type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[df_new[\"make_model\"] == \"Audi A2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.drop(index=[2614], inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[~(df_new.price>35000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.get_dummies(df_new)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.drop(columns = [\"price\"])\n",
    "y= df_new.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso(random_state=42)\n",
    "\n",
    "param_grid = {'alpha':alpha_space}\n",
    "\n",
    "lasso_final_model = GridSearchCV(estimator=lasso_model,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='neg_root_mean_squared_error',\n",
    "                          cv=10,\n",
    "                          n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_final_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_final_model.best_params_  # best alpha for lasso with 6 features : 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_final_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val(lasso_final_model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "# with 6 fetures, r2 score:%86 and %12 error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2230/df_new.price.mean() # error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso_final_model.predict(X_test_scaled)\n",
    "fm_R2 = r2_score(y_test, y_pred)\n",
    "fm_mae = mean_absolute_error(y_test, y_pred)\n",
    "fm_rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYyuZQtWmqZO"
   },
   "source": [
    "## 7. Visually Compare Models Performance In a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\"linear_m\": {\"r2_score\": lm_R2 , \n",
    " \"mae\": lm_mae, \n",
    " \"rmse\": lm_rmse},\n",
    "\n",
    " \"ridge_m\": {\"r2_score\": rm_R2, \n",
    " \"mae\": rm_mae,\n",
    " \"rmse\": rm_rmse},\n",
    "    \n",
    " \"lasso_m\": {\"r2_score\": lasm_R2, \n",
    " \"mae\": lasm_mae, \n",
    " \"rmse\": lasm_rmse},\n",
    "\n",
    " \"elastic_m\": {\"r2_score\": em_R2, \n",
    " \"mae\": em_mae, \n",
    " \"rmse\": em_rmse},\n",
    "         \n",
    " \"final_m\": {\"r2_score\": fm_R2, \n",
    " \"mae\": fm_mae , \n",
    " \"rmse\": fm_rmse}}\n",
    "scores = pd.DataFrame(scores).T\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in scores:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics = scores.columns\n",
    "for i, j in enumerate(scores):\n",
    "    plt.figure(i)\n",
    "    if j == \"r2_score\":\n",
    "        ascending = False\n",
    "    else:\n",
    "        ascending = True\n",
    "    compare = scores.sort_values(by=j, ascending=ascending)\n",
    "    ax = sns.barplot(x = compare[j] , y= compare.index)\n",
    "    for p in ax.patches:\n",
    "            width = p.get_width()                        # get bar length\n",
    "            ax.text(width,                               # set the text at 1 unit right of the bar\n",
    "                    p.get_y() + p.get_height() / 2,      # get Y coordinate + X coordinate / 2\n",
    "                    '{:.4f}'.format(width),             # set variable to display, 2 decimals\n",
    "                    ha = 'left',                         # horizontal alignment\n",
    "                    va = 'center') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction new observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_new.drop(columns = [\"price\"])\n",
    "# y= df_new.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_scaler = MinMaxScaler()\n",
    "# final_scaler.fit(X) # verinin tammamını scaling ediyoruz, train ve testi ayrı ayrı yaplıyoruz çünkü artık modeli deploy edicez\n",
    "# X_scaled = final_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.drop(columns = [\"price\"])\n",
    "y= df_new.price\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "final_scaler = MinMaxScaler()\n",
    "final_scaler.fit(X) # verinin tammamını scaling ediyoruz, train ve testi ayrı ayrı yaplıyoruz çünkü artık modeli deploy edicez\n",
    "X_scaled = final_scaler.transform(X)\n",
    "lasso_model = Lasso(random_state=42)\n",
    "\n",
    "param_grid = {'alpha':alpha_space}\n",
    "\n",
    "final_model = GridSearchCV(estimator=lasso_model,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='neg_root_mean_squared_error',\n",
    "                          cv=10,\n",
    "                          n_jobs = -1)\n",
    "final_model.fit(X_scaled,y)\n",
    "filename = 'finalized_model'\n",
    "pickle.dump(final_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model.fit(X_scaled,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\n",
    "    \"hp_kW\": 66,\n",
    "    \"age\": 2,\n",
    "    \"km\": 17000,\n",
    "    \"make_model\": 'Audi A3',\n",
    "    \"Gearing_Type\": \"Automatic\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = pd.DataFrame([my_dict])\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = pd.get_dummies(my_dict)\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = my_dict.reindex(columns = X.columns, fill_value=0) # yeni sunacağımız veriyi modeldeki sütun düzenine göre ayarlıyoruz\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = final_scaler.transform(my_dict)  # yeni veriyi scaling ediyoruz\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.predict(my_dict) # bu verilere sahip araba 19559$ eder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "modeling_auto_scout_Student_V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
